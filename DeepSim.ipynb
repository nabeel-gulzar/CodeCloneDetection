{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1mB6bJlL9HevbMEnTRiL0PbMmfuWtZhke",
      "authorship_tag": "ABX9TyPk+jWo1uLSxivzfLMvY13B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abcbea8eeea4480f987aad3dcf3b6488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e522023c72ca4d06a21a207cfccb8f3c",
              "IPY_MODEL_2cb9297d66b949b1b83681bea2bb6fe2",
              "IPY_MODEL_f46c41d1a7f7472b8fe1b591c7275399"
            ],
            "layout": "IPY_MODEL_b8b48e77aa04418cb7720ce2a9d9a8c1"
          }
        },
        "e522023c72ca4d06a21a207cfccb8f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a31a3c43f2144c49fb22f4fc316ad9c",
            "placeholder": "​",
            "style": "IPY_MODEL_095c508110344cb2a4f9232d9ff7b921",
            "value": ""
          }
        },
        "2cb9297d66b949b1b83681bea2bb6fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b97984b0b644dd99a18c85cf08dba0d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f3364100c5e4142be6f5c0b8ef79fe1",
            "value": 1
          }
        },
        "f46c41d1a7f7472b8fe1b591c7275399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee5296b99cda4270a6f57a63d83a1a2e",
            "placeholder": "​",
            "style": "IPY_MODEL_96d0ebb9cf5b4617a106cb4418a693d9",
            "value": " 242/? [12:50&lt;00:00,  3.08s/it]"
          }
        },
        "b8b48e77aa04418cb7720ce2a9d9a8c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a31a3c43f2144c49fb22f4fc316ad9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095c508110344cb2a4f9232d9ff7b921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b97984b0b644dd99a18c85cf08dba0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4f3364100c5e4142be6f5c0b8ef79fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee5296b99cda4270a6f57a63d83a1a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d0ebb9cf5b4617a106cb4418a693d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabeel-gulzar/CodeCloneDetection/blob/main/DeepSim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxABEy_1gTUE",
        "outputId": "b95b0f80-8608-4c31-ff60-0ce8f62bc362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepsim'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Total 75 (delta 0), reused 0 (delta 0), pack-reused 75\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/parasol-aser/deepsim.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ7ASptgZ6bq",
        "outputId": "13056812-20aa-49e2-878e-2fb2a76c172e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 16 11:15:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import time\n",
        "from functools import reduce"
      ],
      "metadata": {
        "id": "6kMvZxh8guUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PJpkOHQuL2jo",
        "outputId": "3d4402d8-a494-4eb2-a8b8-6cc43f12a24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aayCLGD9Ntq8",
        "outputId": "0adfaaf3-e3cc-4e89-92e7-5bbf7f483de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tf_slim as slim"
      ],
      "metadata": {
        "id": "Xjo4n7E5NwkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !chmod 755 deepsim/dcsim/encoding/encoding.jar"
      ],
      "metadata": {
        "id": "9Nyy48nUYKkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.path.exists(\"deepsim/dcsim/encoding/encoding.jar\")\n",
        "# !encoding.jar \"hi\"\n",
        "# !deepsim/dcsim/encoding/src/encoding.jar"
      ],
      "metadata": {
        "id": "0Sk01cPjXilQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bin_vec_dim = 88\n",
        "embedding_dim = 6\n",
        "dim = 128\n",
        "keep_prob = 0.75\n",
        "\n",
        "batch_size = 256\n",
        "test_size = 256\n",
        "\n",
        "beta = 0.00003\n",
        "# beta = 0.00001 # for model with batch normalization\n",
        "reg_term = None\n",
        "\n",
        "logdir = '/tmp/tf_logs'"
      ],
      "metadata": {
        "id": "nVMuEL0TNPYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def from_sparse_arr(sparse_arr):\n",
        "    mat = np.zeros((dim, dim, bin_vec_dim), dtype=np.float32)\n",
        "    for (i, j, k) in sparse_arr:\n",
        "        mat[i, j, k] = 1\n",
        "    return mat\n",
        "\n",
        "def from_sparse_arrs(sparse_arrs):\n",
        "    mats = []\n",
        "    for sparse_arr in sparse_arrs:\n",
        "        mats.append(from_sparse_arr(sparse_arr))\n",
        "    mats = np.array(mats, dtype=np.float32)\n",
        "    return mats"
      ],
      "metadata": {
        "id": "eXi9ze8Dw9CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_path = \"/content/deepsim/dataset/g4_128.npy\"\n",
        "# dataset = np.load(open(file_path, 'rb'), allow_pickle=True)\n",
        "# X, y = np.array(dataset['X']), np.array(dataset['y'], dtype='int')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuuOIdXAgsDm",
        "outputId": "370e1954-3d45-48ca-b564-73ec828547a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_act(h, act, phase, scope):\n",
        "    with tf.compat.v1.variable_scope(scope):\n",
        "        return act(h)\n",
        "\n",
        "\n",
        "def variable_summaries(var):\n",
        "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
        "    with tf.name_scope('summaries'):\n",
        "        mean = tf.reduce_mean(var)\n",
        "        tf.summary.scalar('mean', mean)\n",
        "        with tf.name_scope('stddev'):\n",
        "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
        "        tf.summary.scalar('stddev', stddev)\n",
        "        tf.summary.scalar('max', tf.reduce_max(var))\n",
        "        tf.summary.scalar('min', tf.reduce_min(var))\n",
        "        tf.summary.histogram('histogram', var)"
      ],
      "metadata": {
        "id": "fXOJG1mKKXMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X, dropout, phase):\n",
        "    global reg_term\n",
        "    num = tf.shape(X)[0]\n",
        "    with tf.name_scope('emb_layer'):\n",
        "        wf = init_weights([bin_vec_dim, embedding_dim], 'wf')\n",
        "        reg_term = tf.nn.l2_loss(wf)\n",
        "        variable_summaries(wf)\n",
        "        bf = init_bias([embedding_dim], 'bf')\n",
        "        variable_summaries(bf)\n",
        "        X = tf.reshape(X, [num * dim * dim, bin_vec_dim])\n",
        "        h0 = tf.nn.bias_add(tf.matmul(X, wf), bf)\n",
        "        h0 = batch_act(h0, phase=phase, act=tf.nn.elu, scope='emb_layer_bn')\n",
        "        h0 = tf.reshape(h0, [num * dim, dim * embedding_dim])\n",
        "        h0 = tf.nn.dropout(h0, dropout)\n",
        "    with tf.name_scope('row_fc_layer1'):\n",
        "        wr1 = init_weights([embedding_dim * dim, 256], 'wr1')  # 128\n",
        "        reg_term += tf.nn.l2_loss(wr1)\n",
        "        br1 = init_bias([256], 'br1')\n",
        "        h1 = tf.nn.bias_add(tf.matmul(h0, wr1), br1)\n",
        "        h1 = batch_act(h1, phase=phase, act=tf.nn.elu, scope='row_fc_layer1_bn')\n",
        "        h1 = tf.nn.dropout(h1, dropout)\n",
        "    with tf.name_scope('row_fc_layer2'):\n",
        "        wr2 = init_weights([256, 64], 'wr2')  # 32\n",
        "        reg_term += tf.nn.l2_loss(wr2)\n",
        "        br2 = init_bias([64], 'br2')\n",
        "        h2 = tf.nn.bias_add(tf.matmul(h1, wr2), br2)\n",
        "        h2 = batch_act(h2, phase=phase, act=tf.nn.elu, scope='row_fc_layer2_bn')\n",
        "        h2 = tf.reshape(h2, [num, dim, 64])  # 32\n",
        "    with tf.name_scope('avg_pooling'):\n",
        "        h3 = tf.reduce_mean(h2, 1)\n",
        "    return h3"
      ],
      "metadata": {
        "id": "srQ-d27DKLBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(shape, name):\n",
        "    return tf.compat.v1.get_variable(name=name, shape=shape, dtype=tf.float32,\n",
        "                           initializer=slim.variance_scaling_initializer(\n",
        "                               factor=1.0, mode='FAN_AVG', uniform=True))\n",
        "\n",
        "def init_bias(shape, name):\n",
        "    if len(shape) > 1:\n",
        "        raise Exception('Bias should be a vector.')\n",
        "    return tf.compat.v1.get_variable(name=name, shape=shape, dtype=tf.float32,\n",
        "                           initializer=tf.constant_initializer(\n",
        "                               0.01))"
      ],
      "metadata": {
        "id": "pPuXeHsCKQoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification(X1, X2, dropout, phase):\n",
        "    global reg_term\n",
        "    with tf.compat.v1.variable_scope('encoding') as scope:\n",
        "        h31 = model(X1, dropout, phase)\n",
        "        scope.reuse_variables()\n",
        "        h32 = model(X2, dropout, phase)\n",
        "    h41 = tf.concat(values=[h31, h32], axis=1)\n",
        "    with tf.name_scope('fc_layer1_1'):\n",
        "        w5 = init_weights([128, 32], 'w5')  # 64 16\n",
        "        reg_term += tf.nn.l2_loss(w5)\n",
        "        b5 = init_bias([32], 'b5')\n",
        "        h5_1 = tf.nn.bias_add(tf.matmul(h41, w5), b5)\n",
        "        h5_1 = batch_act(h5_1, phase=phase, act=tf.nn.elu,\n",
        "                         scope='fc_layer1_1_bn')\n",
        "    h42 = tf.concat(values=[h32, h31], axis=1)\n",
        "    with tf.name_scope('fc_layer1_2'):\n",
        "        h5_2 = tf.nn.bias_add(tf.matmul(h42, w5), b5)\n",
        "        h5_2 = batch_act(h5_2, phase=phase, act=tf.nn.elu,\n",
        "                         scope='fc_layer1_2_bn')\n",
        "    h5 = (h5_1 + h5_2) / 2.\n",
        "    with tf.name_scope('sm_layer'):\n",
        "        w7 = init_weights([32, 2], 'w7')\n",
        "        reg_term += tf.nn.l2_loss(w7)\n",
        "        variable_summaries(w7)\n",
        "        o = tf.matmul(h5, w7)\n",
        "    return o"
      ],
      "metadata": {
        "id": "Re4cZSFPEXCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs_10_fold(X, Y, pos_ratio = 1.0, neg_ratio=1.0, add_all_neg=False):\n",
        "    indices = np.random.permutation(np.shape(Y)[0])\n",
        "    X = np.array(X)[indices]\n",
        "    Y = np.array(Y, dtype=np.int)[indices]\n",
        "    y_dist = np.bincount(Y)\n",
        "    positive_count = reduce(lambda n1, n2: n1+n2, map(lambda num: num*num/2,\n",
        "                                          y_dist.tolist()))\n",
        "    X_left = []\n",
        "    X_right = []\n",
        "    trainY = []\n",
        "    p = positive_count * neg_ratio * pos_ratio / (len(X) * len(X) / 2)\n",
        "    for i in range(len(X)):\n",
        "        for j in range(i + 1, len(X)):\n",
        "            if Y[i] == Y[j] and np.random.rand(1)[0] <= pos_ratio:\n",
        "                X_left.append(X[i])\n",
        "                X_right.append(X[j])\n",
        "                trainY.append([0, 1])\n",
        "            elif np.random.rand(1)[0] <= p or add_all_neg:\n",
        "                X_left.append(X[i])\n",
        "                X_right.append(X[j])\n",
        "                trainY.append([1, 0])\n",
        "\n",
        "    indices = np.random.permutation(np.shape(trainY)[0])\n",
        "    sample_X_left = np.array(X_left)[indices]\n",
        "    sample_X_right = np.array(X_right)[indices]\n",
        "    sample_Y = np.array(trainY, dtype=np.float32)[indices]\n",
        "    return sample_X_left, sample_X_right, sample_Y"
      ],
      "metadata": {
        "id": "zpIX3CT9GGhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stat(Y, predicted_Y, fout=None):\n",
        "    real_positive_count = 0\n",
        "    predict_positive_count = 0\n",
        "    recall = 0\n",
        "    precision = 0\n",
        "    print(f\"True Predictions: {predicted_Y.sum()}\")\n",
        "    for i in range(Y.shape[0]):\n",
        "        if Y[i] == 1:\n",
        "            real_positive_count += 1\n",
        "            if predicted_Y[i] == 1:\n",
        "                recall += 1\n",
        "        if predicted_Y[i] == 1:\n",
        "            predict_positive_count += 1\n",
        "            if Y[i] == 1:\n",
        "                precision += 1\n",
        "    retrieved_positive_count = recall\n",
        "    recall /= real_positive_count * 1.0\n",
        "    precision /= max(predict_positive_count * 1.0, 1.0)\n",
        "    f1_score = 2 * recall * precision / max(\n",
        "    recall + precision, 0.00001)\n",
        "    print(f\"Clone pairs: {real_positive_count}, non-clone pairs: {Y.shape[0] - real_positive_count}\")\n",
        "    print(f\"Recall: {recall}, precision: {precision}, f1 score: {f1_score}\")\n",
        "    print(f\"Predicted_positive_count: {predict_positive_count}, recall truly positive: {retrieved_positive_count}\")\n",
        "    print(f\"false positive: {predict_positive_count - retrieved_positive_count}\")\n",
        "    print(f\"missed true positive: {real_positive_count - retrieved_positive_count}\")\n",
        "    if fout is not None:\n",
        "        fout.write(f\"Clone pairs: {real_positive_count}, non-clone pairs: {Y.shape[0] - real_positive_count}\\n\")\n",
        "        fout.write(f\"Recall: {recall:.4f}, precision: {precision:.4f}, f1 score: {f1_score:.4f}\\n\")\n",
        "        fout.write(f\"Predicted_positive_count: {predict_positive_count}, recall truly positive: {retrieved_positive_count}, \")\n",
        "        fout.write(f\"false positive: {predict_positive_count - retrieved_positive_count}, missed true positive: {real_positive_count - retrieved_positive_count}\\n\")\n",
        "    return recall, precision, f1_score"
      ],
      "metadata": {
        "id": "to8yxBqgGcWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "VEa_gB5yIiqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.name_scope('input'):\n",
        "    X_left = tf.compat.v1.placeholder(tf.float32, [None, dim, dim, bin_vec_dim])\n",
        "    X_right = tf.compat.v1.placeholder(tf.float32, [None, dim, dim, bin_vec_dim])\n",
        "    Y = tf.compat.v1.placeholder(tf.float32, [None, 2])\n",
        "dropout = tf.compat.v1.placeholder(tf.float32)\n",
        "phase = tf.compat.v1.placeholder(tf.bool, name='phase')\n",
        "sample_weights = tf.compat.v1.placeholder(tf.float32, [batch_size])"
      ],
      "metadata": {
        "id": "wVKivW6ZIOkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py_x = classification(X_left, X_right, dropout, phase)"
      ],
      "metadata": {
        "id": "Rr7zZrvPItSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbf1e7zIONIa",
        "outputId": "bfe579a6-f533-4cad-e2cb-01424204cb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'sm_layer/MatMul:0' shape=(None, 2) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(\n",
        "    tf.compat.v1.losses.softmax_cross_entropy(logits=py_x, onehot_labels=Y,\n",
        "                                    weights=sample_weights))"
      ],
      "metadata": {
        "id": "EmVRw6soOW8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.summary.scalar('cost', cost)\n",
        "cost = tf.reduce_mean(cost + beta * reg_term)\n",
        "update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)"
      ],
      "metadata": {
        "id": "PLt8OEspQZ6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.control_dependencies(update_ops):\n",
        "    train_op = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001).minimize(\n",
        "        cost)\n",
        "    predict_op = tf.argmax(py_x, 1)"
      ],
      "metadata": {
        "id": "DRxalntKQhgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=10)"
      ],
      "metadata": {
        "id": "Z0sO9xmFQvCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/deepsim/dataset/g4_128.npy\"\n",
        "dataset = np.load(open(file_path, 'rb'), allow_pickle=True)\n",
        "X, y = np.array(dataset['X']), np.array(dataset['y'], dtype='int')\n",
        "\n",
        "# shuffle\n",
        "indices = np.random.permutation(X.shape[0])\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "fold_index = 0\n",
        "avg_accuracy = 0.\n",
        "avg_recall = 0.\n",
        "avg_precision = 0.\n",
        "avg_f1_score = 0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwYFWJsXQyCe",
        "outputId": "bb63d345-3f8b-4a11-cfeb-31f45ee95334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf 10_fold_balanced/\n",
        "if os.path.exists('result') is not True:\n",
        "    os.mkdir(\"result\")\n",
        "if os.path.exists(\"10_fold_balanced\") is not True:\n",
        "    os.mkdir(\"10_fold_balanced\")\n",
        "fout = open('result/10_fold_balanced.txt', 'w')"
      ],
      "metadata": {
        "id": "QSKF3m5dQ_rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# tf.compat.v1.summary.merge_all"
      ],
      "metadata": {
        "id": "12pocGH9SQRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_index = 0\n",
        "\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "    print ('*' * 40 + str(fold_index) + '*' * 40)\n",
        "    fold_path = os.path.join(\"10_fold_balanced\", str(fold_index))\n",
        "    if os.path.exists(fold_path) is not True:\n",
        "        os.mkdir(fold_path)\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    train_X_left, train_X_right, train_Y = \\\n",
        "        make_pairs_10_fold(X_train, y_train, neg_ratio=10.0,\n",
        "                                          pos_ratio=1.0, add_all_neg=True)\n",
        "    test_X_left, test_X_right, test_Y = \\\n",
        "        make_pairs_10_fold(X_test, y_test, neg_ratio=1.0,\n",
        "                                          pos_ratio=1.0, add_all_neg=True)\n",
        "\n",
        "    # compute the class weights\n",
        "    classes_numbers = np.bincount(np.argmax(train_Y, axis=1))\n",
        "    classes_weights = np.array([classes_numbers[1] * 2.0 /\n",
        "                                  (classes_numbers[0] + classes_numbers[1]),\n",
        "                                  classes_numbers[0] * 1.0 /\n",
        "                                  (classes_numbers[0] + classes_numbers[1])],\n",
        "                                dtype=np.float32)\n",
        "    classes_weights = np.reshape(classes_weights, newshape=[2,1])\n",
        "\n",
        "    t_beg = time.process_time()\n",
        "    # tf.reset_default_graph() # reset the model\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "        sess.run(tf.compat.v1.local_variables_initializer())\n",
        "        merged = tf.compat.v1.summary.merge_all()\n",
        "        train_writer = tf.compat.v1.summary.FileWriter(\n",
        "            logdir, sess.graph)\n",
        "        saver = tf.compat.v1.train.Saver(max_to_keep=3)\n",
        "        for epoch in range(4):\n",
        "            # re-shuffle for each epoch\n",
        "            # print(f\"epoch: {epoch}\")\n",
        "            indices = np.random.permutation(train_X_left.shape[0])\n",
        "            train_X_left = train_X_left[indices]\n",
        "            train_X_right = train_X_right[indices]\n",
        "            train_Y = train_Y[indices]\n",
        "            # for small test\n",
        "            dense_test_X_left = from_sparse_arrs(test_X_left[0:test_size])\n",
        "            dense_test_X_right = from_sparse_arrs(test_X_right[0:test_size])\n",
        "            n_examples = train_X_left.shape[0]\n",
        "            n_batches = ceil(n_examples/batch_size)\n",
        "            step = 0\n",
        "            for start, end in tqdm(zip(\n",
        "                    range(0, np.shape(train_X_left)[0], batch_size),\n",
        "                    range(batch_size, np.shape(train_X_left)[0] + 1,\n",
        "                          batch_size))):\n",
        "                dense_train_X_left = from_sparse_arrs(\n",
        "                    train_X_left[start:end])\n",
        "                dense_train_X_right = from_sparse_arrs(\n",
        "                    train_X_right[start:end])\n",
        "                batch_samples_weights = np.matmul(train_Y[start:end],\n",
        "                                                  classes_weights)\n",
        "                batch_samples_weights = np.reshape(batch_samples_weights,\n",
        "                                                    newshape=[batch_size])\n",
        "                _ = sess.run([train_op],\n",
        "                                      feed_dict={X_left: dense_train_X_left,\n",
        "                                                  X_right: dense_train_X_right,\n",
        "                                                  Y: train_Y[start:end],\n",
        "                                                  sample_weights:\n",
        "                                                      batch_samples_weights,\n",
        "                                                  dropout: keep_prob,\n",
        "                                                  phase: 1})\n",
        "                print('epoch %d, iteration %d/%d\\n' % (epoch, step, n_batches))\n",
        "                step += 1\n",
        "                # if step % 100 == 0 and step != 0:\n",
        "                #     batch_samples_weights = np.matmul(test_Y[:test_size],\n",
        "                #                                       classes_weights)\n",
        "                #     batch_samples_weights = np.reshape(\n",
        "                #         batch_samples_weights,\n",
        "                #         newshape=[test_size])\n",
        "                #     predict_Y, summary = sess.run([predict_op, merged],\n",
        "                #                           feed_dict={\n",
        "                #                               X_left: dense_test_X_left,\n",
        "                #                               X_right: dense_test_X_right,\n",
        "                #                               Y: test_Y[:test_size],\n",
        "                #                               sample_weights:batch_samples_weights,\n",
        "                #                               dropout: 1.0,\n",
        "                #                               phase: 0})  # no dropout\n",
        "                #     train_writer.add_summary(summary, step)\n",
        "                #     print(epoch, np.mean(\n",
        "                #         np.argmax(test_Y[:test_size], axis=1) == predict_Y))\n",
        "        saver.save(sess, os.path.join(fold_path, 'mode.ckpt'))\n",
        "        print(\"model saved.\")\n",
        "        t_end = time.process_time()\n",
        "        print('Time cost: %.2f' % (t_end - t_beg))\n",
        "\n",
        "        # validation\n",
        "        overall_accuracy = 0.\n",
        "        overall_predict_Y = []\n",
        "        iter = 0\n",
        "\n",
        "        print(f\"{'*'*20}Evaluation{'*'*20}\")\n",
        "        for start, end in zip(\n",
        "                range(0, np.shape(test_X_left)[0], batch_size),\n",
        "                range(batch_size, np.shape(test_X_left)[0] + 1,\n",
        "                      batch_size)):\n",
        "            dense_test_X_left = from_sparse_arrs(test_X_left[start:end])\n",
        "            dense_test_X_right = from_sparse_arrs(test_X_right[start:end])\n",
        "            predict_Y = sess.run(predict_op,\n",
        "                                  feed_dict={X_left: dense_test_X_left,\n",
        "                                            X_right: dense_test_X_right,\n",
        "                                            dropout: 1.0,\n",
        "                                            phase: 0})  # no dropout\n",
        "            overall_predict_Y.extend(predict_Y.tolist())\n",
        "            accuracy = np.mean(\n",
        "                np.argmax(test_Y[start:end], axis=1) == predict_Y)\n",
        "            iter += 1\n",
        "            overall_accuracy += accuracy\n",
        "\n",
        "        print('Overall accuracy: %.5f' % (overall_accuracy / iter))\n",
        "        t_end = time.process_time()\n",
        "        print('Time cost: %.2f' % (t_end - t_beg))\n",
        "        fout.write('*' * 80 + '\\n')\n",
        "        fout.write('Fold %d:\\n' % (fold_index))\n",
        "        fout.write('Overall accuracy: %.5f\\n' % (overall_accuracy / iter))\n",
        "        fout.write('Time cost: %.2f\\n' % (t_end - t_beg))\n",
        "        recall, precision, f1_score = stat(\n",
        "            np.argmax(test_Y[:len(overall_predict_Y)], axis=1),\n",
        "            np.array(overall_predict_Y, dtype='int'), fout=fout)\n",
        "        fout.flush()\n",
        "        avg_accuracy += overall_accuracy / iter\n",
        "        avg_recall += recall\n",
        "        avg_precision += precision\n",
        "        avg_f1_score += f1_score\n",
        "    print('*' * 80)\n",
        "    fold_index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "abcbea8eeea4480f987aad3dcf3b6488",
            "e522023c72ca4d06a21a207cfccb8f3c",
            "2cb9297d66b949b1b83681bea2bb6fe2",
            "f46c41d1a7f7472b8fe1b591c7275399",
            "b8b48e77aa04418cb7720ce2a9d9a8c1",
            "2a31a3c43f2144c49fb22f4fc316ad9c",
            "095c508110344cb2a4f9232d9ff7b921",
            "1b97984b0b644dd99a18c85cf08dba0d",
            "4f3364100c5e4142be6f5c0b8ef79fe1",
            "ee5296b99cda4270a6f57a63d83a1a2e",
            "96d0ebb9cf5b4617a106cb4418a693d9"
          ]
        },
        "id": "UcAwrk6BHrjK",
        "outputId": "67908ad2-dc18-4cbf-c584-36fc77c6144f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************0****************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abcbea8eeea4480f987aad3dcf3b6488"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, iteration 0/4404\n",
            "\n",
            "epoch 0, iteration 1/4404\n",
            "\n",
            "epoch 0, iteration 2/4404\n",
            "\n",
            "epoch 0, iteration 3/4404\n",
            "\n",
            "epoch 0, iteration 4/4404\n",
            "\n",
            "epoch 0, iteration 5/4404\n",
            "\n",
            "epoch 0, iteration 6/4404\n",
            "\n",
            "epoch 0, iteration 7/4404\n",
            "\n",
            "epoch 0, iteration 8/4404\n",
            "\n",
            "epoch 0, iteration 9/4404\n",
            "\n",
            "epoch 0, iteration 10/4404\n",
            "\n",
            "epoch 0, iteration 11/4404\n",
            "\n",
            "epoch 0, iteration 12/4404\n",
            "\n",
            "epoch 0, iteration 13/4404\n",
            "\n",
            "epoch 0, iteration 14/4404\n",
            "\n",
            "epoch 0, iteration 15/4404\n",
            "\n",
            "epoch 0, iteration 16/4404\n",
            "\n",
            "epoch 0, iteration 17/4404\n",
            "\n",
            "epoch 0, iteration 18/4404\n",
            "\n",
            "epoch 0, iteration 19/4404\n",
            "\n",
            "epoch 0, iteration 20/4404\n",
            "\n",
            "epoch 0, iteration 21/4404\n",
            "\n",
            "epoch 0, iteration 22/4404\n",
            "\n",
            "epoch 0, iteration 23/4404\n",
            "\n",
            "epoch 0, iteration 24/4404\n",
            "\n",
            "epoch 0, iteration 25/4404\n",
            "\n",
            "epoch 0, iteration 26/4404\n",
            "\n",
            "epoch 0, iteration 27/4404\n",
            "\n",
            "epoch 0, iteration 28/4404\n",
            "\n",
            "epoch 0, iteration 29/4404\n",
            "\n",
            "epoch 0, iteration 30/4404\n",
            "\n",
            "epoch 0, iteration 31/4404\n",
            "\n",
            "epoch 0, iteration 32/4404\n",
            "\n",
            "epoch 0, iteration 33/4404\n",
            "\n",
            "epoch 0, iteration 34/4404\n",
            "\n",
            "epoch 0, iteration 35/4404\n",
            "\n",
            "epoch 0, iteration 36/4404\n",
            "\n",
            "epoch 0, iteration 37/4404\n",
            "\n",
            "epoch 0, iteration 38/4404\n",
            "\n",
            "epoch 0, iteration 39/4404\n",
            "\n",
            "epoch 0, iteration 40/4404\n",
            "\n",
            "epoch 0, iteration 41/4404\n",
            "\n",
            "epoch 0, iteration 42/4404\n",
            "\n",
            "epoch 0, iteration 43/4404\n",
            "\n",
            "epoch 0, iteration 44/4404\n",
            "\n",
            "epoch 0, iteration 45/4404\n",
            "\n",
            "epoch 0, iteration 46/4404\n",
            "\n",
            "epoch 0, iteration 47/4404\n",
            "\n",
            "epoch 0, iteration 48/4404\n",
            "\n",
            "epoch 0, iteration 49/4404\n",
            "\n",
            "epoch 0, iteration 50/4404\n",
            "\n",
            "epoch 0, iteration 51/4404\n",
            "\n",
            "epoch 0, iteration 52/4404\n",
            "\n",
            "epoch 0, iteration 53/4404\n",
            "\n",
            "epoch 0, iteration 54/4404\n",
            "\n",
            "epoch 0, iteration 55/4404\n",
            "\n",
            "epoch 0, iteration 56/4404\n",
            "\n",
            "epoch 0, iteration 57/4404\n",
            "\n",
            "epoch 0, iteration 58/4404\n",
            "\n",
            "epoch 0, iteration 59/4404\n",
            "\n",
            "epoch 0, iteration 60/4404\n",
            "\n",
            "epoch 0, iteration 61/4404\n",
            "\n",
            "epoch 0, iteration 62/4404\n",
            "\n",
            "epoch 0, iteration 63/4404\n",
            "\n",
            "epoch 0, iteration 64/4404\n",
            "\n",
            "epoch 0, iteration 65/4404\n",
            "\n",
            "epoch 0, iteration 66/4404\n",
            "\n",
            "epoch 0, iteration 67/4404\n",
            "\n",
            "epoch 0, iteration 68/4404\n",
            "\n",
            "epoch 0, iteration 69/4404\n",
            "\n",
            "epoch 0, iteration 70/4404\n",
            "\n",
            "epoch 0, iteration 71/4404\n",
            "\n",
            "epoch 0, iteration 72/4404\n",
            "\n",
            "epoch 0, iteration 73/4404\n",
            "\n",
            "epoch 0, iteration 74/4404\n",
            "\n",
            "epoch 0, iteration 75/4404\n",
            "\n",
            "epoch 0, iteration 76/4404\n",
            "\n",
            "epoch 0, iteration 77/4404\n",
            "\n",
            "epoch 0, iteration 78/4404\n",
            "\n",
            "epoch 0, iteration 79/4404\n",
            "\n",
            "epoch 0, iteration 80/4404\n",
            "\n",
            "epoch 0, iteration 81/4404\n",
            "\n",
            "epoch 0, iteration 82/4404\n",
            "\n",
            "epoch 0, iteration 83/4404\n",
            "\n",
            "epoch 0, iteration 84/4404\n",
            "\n",
            "epoch 0, iteration 85/4404\n",
            "\n",
            "epoch 0, iteration 86/4404\n",
            "\n",
            "epoch 0, iteration 87/4404\n",
            "\n",
            "epoch 0, iteration 88/4404\n",
            "\n",
            "epoch 0, iteration 89/4404\n",
            "\n",
            "epoch 0, iteration 90/4404\n",
            "\n",
            "epoch 0, iteration 91/4404\n",
            "\n",
            "epoch 0, iteration 92/4404\n",
            "\n",
            "epoch 0, iteration 93/4404\n",
            "\n",
            "epoch 0, iteration 94/4404\n",
            "\n",
            "epoch 0, iteration 95/4404\n",
            "\n",
            "epoch 0, iteration 96/4404\n",
            "\n",
            "epoch 0, iteration 97/4404\n",
            "\n",
            "epoch 0, iteration 98/4404\n",
            "\n",
            "epoch 0, iteration 99/4404\n",
            "\n",
            "epoch 0, iteration 100/4404\n",
            "\n",
            "epoch 0, iteration 101/4404\n",
            "\n",
            "epoch 0, iteration 102/4404\n",
            "\n",
            "epoch 0, iteration 103/4404\n",
            "\n",
            "epoch 0, iteration 104/4404\n",
            "\n",
            "epoch 0, iteration 105/4404\n",
            "\n",
            "epoch 0, iteration 106/4404\n",
            "\n",
            "epoch 0, iteration 107/4404\n",
            "\n",
            "epoch 0, iteration 108/4404\n",
            "\n",
            "epoch 0, iteration 109/4404\n",
            "\n",
            "epoch 0, iteration 110/4404\n",
            "\n",
            "epoch 0, iteration 111/4404\n",
            "\n",
            "epoch 0, iteration 112/4404\n",
            "\n",
            "epoch 0, iteration 113/4404\n",
            "\n",
            "epoch 0, iteration 114/4404\n",
            "\n",
            "epoch 0, iteration 115/4404\n",
            "\n",
            "epoch 0, iteration 116/4404\n",
            "\n",
            "epoch 0, iteration 117/4404\n",
            "\n",
            "epoch 0, iteration 118/4404\n",
            "\n",
            "epoch 0, iteration 119/4404\n",
            "\n",
            "epoch 0, iteration 120/4404\n",
            "\n",
            "epoch 0, iteration 121/4404\n",
            "\n",
            "epoch 0, iteration 122/4404\n",
            "\n",
            "epoch 0, iteration 123/4404\n",
            "\n",
            "epoch 0, iteration 124/4404\n",
            "\n",
            "epoch 0, iteration 125/4404\n",
            "\n",
            "epoch 0, iteration 126/4404\n",
            "\n",
            "epoch 0, iteration 127/4404\n",
            "\n",
            "epoch 0, iteration 128/4404\n",
            "\n",
            "epoch 0, iteration 129/4404\n",
            "\n",
            "epoch 0, iteration 130/4404\n",
            "\n",
            "epoch 0, iteration 131/4404\n",
            "\n",
            "epoch 0, iteration 132/4404\n",
            "\n",
            "epoch 0, iteration 133/4404\n",
            "\n",
            "epoch 0, iteration 134/4404\n",
            "\n",
            "epoch 0, iteration 135/4404\n",
            "\n",
            "epoch 0, iteration 136/4404\n",
            "\n",
            "epoch 0, iteration 137/4404\n",
            "\n",
            "epoch 0, iteration 138/4404\n",
            "\n",
            "epoch 0, iteration 139/4404\n",
            "\n",
            "epoch 0, iteration 140/4404\n",
            "\n",
            "epoch 0, iteration 141/4404\n",
            "\n",
            "epoch 0, iteration 142/4404\n",
            "\n",
            "epoch 0, iteration 143/4404\n",
            "\n",
            "epoch 0, iteration 144/4404\n",
            "\n",
            "epoch 0, iteration 145/4404\n",
            "\n",
            "epoch 0, iteration 146/4404\n",
            "\n",
            "epoch 0, iteration 147/4404\n",
            "\n",
            "epoch 0, iteration 148/4404\n",
            "\n",
            "epoch 0, iteration 149/4404\n",
            "\n",
            "epoch 0, iteration 150/4404\n",
            "\n",
            "epoch 0, iteration 151/4404\n",
            "\n",
            "epoch 0, iteration 152/4404\n",
            "\n",
            "epoch 0, iteration 153/4404\n",
            "\n",
            "epoch 0, iteration 154/4404\n",
            "\n",
            "epoch 0, iteration 155/4404\n",
            "\n",
            "epoch 0, iteration 156/4404\n",
            "\n",
            "epoch 0, iteration 157/4404\n",
            "\n",
            "epoch 0, iteration 158/4404\n",
            "\n",
            "epoch 0, iteration 159/4404\n",
            "\n",
            "epoch 0, iteration 160/4404\n",
            "\n",
            "epoch 0, iteration 161/4404\n",
            "\n",
            "epoch 0, iteration 162/4404\n",
            "\n",
            "epoch 0, iteration 163/4404\n",
            "\n",
            "epoch 0, iteration 164/4404\n",
            "\n",
            "epoch 0, iteration 165/4404\n",
            "\n",
            "epoch 0, iteration 166/4404\n",
            "\n",
            "epoch 0, iteration 167/4404\n",
            "\n",
            "epoch 0, iteration 168/4404\n",
            "\n",
            "epoch 0, iteration 169/4404\n",
            "\n",
            "epoch 0, iteration 170/4404\n",
            "\n",
            "epoch 0, iteration 171/4404\n",
            "\n",
            "epoch 0, iteration 172/4404\n",
            "\n",
            "epoch 0, iteration 173/4404\n",
            "\n",
            "epoch 0, iteration 174/4404\n",
            "\n",
            "epoch 0, iteration 175/4404\n",
            "\n",
            "epoch 0, iteration 176/4404\n",
            "\n",
            "epoch 0, iteration 177/4404\n",
            "\n",
            "epoch 0, iteration 178/4404\n",
            "\n",
            "epoch 0, iteration 179/4404\n",
            "\n",
            "epoch 0, iteration 180/4404\n",
            "\n",
            "epoch 0, iteration 181/4404\n",
            "\n",
            "epoch 0, iteration 182/4404\n",
            "\n",
            "epoch 0, iteration 183/4404\n",
            "\n",
            "epoch 0, iteration 184/4404\n",
            "\n",
            "epoch 0, iteration 185/4404\n",
            "\n",
            "epoch 0, iteration 186/4404\n",
            "\n",
            "epoch 0, iteration 187/4404\n",
            "\n",
            "epoch 0, iteration 188/4404\n",
            "\n",
            "epoch 0, iteration 189/4404\n",
            "\n",
            "epoch 0, iteration 190/4404\n",
            "\n",
            "epoch 0, iteration 191/4404\n",
            "\n",
            "epoch 0, iteration 192/4404\n",
            "\n",
            "epoch 0, iteration 193/4404\n",
            "\n",
            "epoch 0, iteration 194/4404\n",
            "\n",
            "epoch 0, iteration 195/4404\n",
            "\n",
            "epoch 0, iteration 196/4404\n",
            "\n",
            "epoch 0, iteration 197/4404\n",
            "\n",
            "epoch 0, iteration 198/4404\n",
            "\n",
            "epoch 0, iteration 199/4404\n",
            "\n",
            "epoch 0, iteration 200/4404\n",
            "\n",
            "epoch 0, iteration 201/4404\n",
            "\n",
            "epoch 0, iteration 202/4404\n",
            "\n",
            "epoch 0, iteration 203/4404\n",
            "\n",
            "epoch 0, iteration 204/4404\n",
            "\n",
            "epoch 0, iteration 205/4404\n",
            "\n",
            "epoch 0, iteration 206/4404\n",
            "\n",
            "epoch 0, iteration 207/4404\n",
            "\n",
            "epoch 0, iteration 208/4404\n",
            "\n",
            "epoch 0, iteration 209/4404\n",
            "\n",
            "epoch 0, iteration 210/4404\n",
            "\n",
            "epoch 0, iteration 211/4404\n",
            "\n",
            "epoch 0, iteration 212/4404\n",
            "\n",
            "epoch 0, iteration 213/4404\n",
            "\n",
            "epoch 0, iteration 214/4404\n",
            "\n",
            "epoch 0, iteration 215/4404\n",
            "\n",
            "epoch 0, iteration 216/4404\n",
            "\n",
            "epoch 0, iteration 217/4404\n",
            "\n",
            "epoch 0, iteration 218/4404\n",
            "\n",
            "epoch 0, iteration 219/4404\n",
            "\n",
            "epoch 0, iteration 220/4404\n",
            "\n",
            "epoch 0, iteration 221/4404\n",
            "\n",
            "epoch 0, iteration 222/4404\n",
            "\n",
            "epoch 0, iteration 223/4404\n",
            "\n",
            "epoch 0, iteration 224/4404\n",
            "\n",
            "epoch 0, iteration 225/4404\n",
            "\n",
            "epoch 0, iteration 226/4404\n",
            "\n",
            "epoch 0, iteration 227/4404\n",
            "\n",
            "epoch 0, iteration 228/4404\n",
            "\n",
            "epoch 0, iteration 229/4404\n",
            "\n",
            "epoch 0, iteration 230/4404\n",
            "\n",
            "epoch 0, iteration 231/4404\n",
            "\n",
            "epoch 0, iteration 232/4404\n",
            "\n",
            "epoch 0, iteration 233/4404\n",
            "\n",
            "epoch 0, iteration 234/4404\n",
            "\n",
            "epoch 0, iteration 235/4404\n",
            "\n",
            "epoch 0, iteration 236/4404\n",
            "\n",
            "epoch 0, iteration 237/4404\n",
            "\n",
            "epoch 0, iteration 238/4404\n",
            "\n",
            "epoch 0, iteration 239/4404\n",
            "\n",
            "epoch 0, iteration 240/4404\n",
            "\n",
            "epoch 0, iteration 241/4404\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_accuracy /= 10.0\n",
        "avg_precision /= 10.0\n",
        "avg_recall /= 10.0\n",
        "avg_f1_score /= 10.0\n",
        "print('Avg accuracy: %.4f, avg recall: %.4f, avg precision: %.4f, avg f1 '\n",
        "      'score: %.4f' % (\n",
        "      avg_accuracy, avg_recall, avg_precision, avg_f1_score))\n",
        "fout.write('*' * 80 + '\\n')\n",
        "fout.write(\n",
        "    'Avg accuracy: %.4f, avg recall: %.4f, avg precision: %.4f, avg f1 '\n",
        "    'score: %.4f' % (avg_accuracy, avg_recall, avg_precision, avg_f1_score))\n",
        "fout.close()"
      ],
      "metadata": {
        "id": "mq_5Vh2CRUxi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}